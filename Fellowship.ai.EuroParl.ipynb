{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FELLOWSHIP.AI - EUROPARL DATASET\n",
    "\n",
    "## INTRODUCTION \n",
    "\n",
    "### Project was done as a challenge requirement for the Fellowship.AI machine learning fellow application. Data for the project was collected from 2 places: training data was collected from http://www.statmt.org/europarl/ from the link titled \"source releast (text files), 1.5 GB\" and the testing data was collected from the website of fellowship.ai, from the challenge tab. Majority of time was spent on data extraction, cleaning and pre-processing. \n",
    "\n",
    "## DATA EXTRACTION \n",
    "\n",
    "### The source release (text files) data was downloaded in .tgz format. This was unzipped to get the europarl.tar file. Contents of this file were extracted using the python tarfile library. This extraction setup a folder called txt in the working directory. This folder had 21 sub-folders, one for each european language. Each of these sub-folders had thousands of text files. The files contain text from the european parliament in the 21 different languages.\n",
    "\n",
    "### A small sample of text files were imported for use as training data. Data was extracted using the train_extract and train_extract1 functions. Only difference between the 2 functions is the number of files they import. While train_extract extracts 1000 files, train_extract1 extracts only 10 files from the sub-folder. The 2 different functions were used on different sets of languages. Some languages have text files with many hundreds of lines while some languages have text files with very few lines. The different functions ensure that the training text corpora for different languages have similar distribution of words.\n",
    "\n",
    "## DATA CLEANUP\n",
    "\n",
    "### The training dataset contained html type tags <> with text inside them. The text contains chapter names, speaker names etc. The tags and everything inside them were cleaned up using regex. After this, the training data for each language was sentence tokenized. Further, a dataframe with these sentences as one column and the respective language in the other column was created. While the train_extract function was called for each language, I realize that this is an inefficient way to write code. I end up having 21 similar code blocks. I think a better way to do this would have been to use a recursive glob function that would match the name of the sub-folder and the language argument of the train_extract function. The language argument would be a list containing all 21 languages. The function could loop over the sub-folders and check if the sub-folder matches with the language in the list. If they do, the new column would be populated with the name of that respective language. \n",
    "\n",
    "### The format of the testing data was a single text file containing text corpora in all 21 languages in alphabetical order of languages. Each sentence, at the start, had a prefix indicating the language of the sentence. The testing data was first sentence tokenized. After this, regex was used to extract each prefix from every sentence. Further, a dataframe was created where one column was the sentences in different languages and the other column contained the language prefix. Finally, NA values were backfilled.\n",
    "\n",
    "## FEATURE ENGINEERING\n",
    "\n",
    "### No feature engineering was done since the classifier tries to classify based on language text. Due to the nature of the problem statement, it was felt that feature engineering was not required.\n",
    "\n",
    "## MACHINE LEARNING\n",
    "\n",
    "### Naive Bayes classifier was used to build the model. Training data was first run through a count vectorizer. After this, the model was built using the training set. This model was further validated on the holdout set, giving an accuracy of 98.87%. Finally, the model was run on the actual testing set, giving an accuracy of 96.08%. From here, a separate dataset was built by extracting out only the misclassified instances. A misclassification table shows that the highest rate of misclassification happened when the model classified the language as Danish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to extract training data, \n",
    "# sentence tokenize and build new feature called language, showing the respective european language\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import itertools\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "def train_extract(file_list,lang):\n",
    "        \n",
    "    train=[]\n",
    "\n",
    "    for file_path in file_list[:1000]:\n",
    "        with open(file_path,encoding='utf8') as f_input:\n",
    "            train.append(f_input.read())\n",
    "\n",
    "    train_clean=[re.sub(r'(.*?\\<(.*)>.*|\\n)','',i).strip() for i in train]\n",
    "\n",
    "    train_clean=[re.sub(r\"'\",'',i).strip() for i in train_clean]\n",
    "        \n",
    "    train_clean1=''.join(train_clean)\n",
    "\n",
    "    train_token=pd.Series(nltk.sent_tokenize(train_clean1))\n",
    "\n",
    "    train_token1=pd.DataFrame(train_token)\n",
    "\n",
    "    train_token1['Language']=lang\n",
    "\n",
    "    return train_token1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same purpose as above function but imports only 1 file to ensure \n",
    "# equal distribution of words across languages\n",
    "\n",
    "def train_extract1(file_list,lang):\n",
    "        \n",
    "    train=[]\n",
    "\n",
    "    for file_path in file_list[:1]:\n",
    "        with open(file_path,encoding='utf8') as f_input:\n",
    "            train.append(f_input.read())\n",
    "\n",
    "    train_clean=[re.sub(r'(.*?\\<(.*)>.*|\\n)','',i).strip() for i in train]\n",
    "\n",
    "    train_clean=[re.sub(r\"'\",'',i).strip() for i in train_clean]\n",
    "        \n",
    "    train_clean1=''.join(train_clean)\n",
    "\n",
    "    train_token=pd.Series(nltk.sent_tokenize(train_clean1))\n",
    "\n",
    "    train_token1=pd.DataFrame(train_token)\n",
    "\n",
    "    train_token1['Language']=lang\n",
    "\n",
    "    return train_token1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Bulgarian\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/bg/*.txt', recursive=True)\n",
    "\n",
    "lang='bg'\n",
    "\n",
    "train_bg=train_extract(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Czech\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/cs/*.txt', recursive=True)\n",
    "\n",
    "lang='cs'\n",
    "\n",
    "train_cs=train_extract(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Danish\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/da/*.txt', recursive=True)\n",
    "\n",
    "lang='da'\n",
    "\n",
    "train_da=train_extract1(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract German\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/de/*.txt', recursive=True)\n",
    "\n",
    "lang='de'\n",
    "\n",
    "train_de=train_extract1(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Greek\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/el/*.txt', recursive=True)\n",
    "\n",
    "lang='el'\n",
    "\n",
    "train_el=train_extract1(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract English\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/en/*.txt', recursive=True)\n",
    "\n",
    "lang='en'\n",
    "\n",
    "train_en=train_extract1(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Spanish\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/es/*.txt', recursive=True)\n",
    "\n",
    "lang='es'\n",
    "\n",
    "train_es=train_extract1(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Estonian\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/et/*.txt', recursive=True)\n",
    "\n",
    "lang='et'\n",
    "\n",
    "train_et=train_extract(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Finnish\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/fi/*.txt', recursive=True)\n",
    "\n",
    "lang='fi'\n",
    "\n",
    "train_fi=train_extract1(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract French\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/fr/*.txt', recursive=True)\n",
    "\n",
    "lang='fr'\n",
    "\n",
    "train_fr=train_extract1(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Hungarian\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/hu/*.txt', recursive=True)\n",
    "\n",
    "lang='hu'\n",
    "\n",
    "train_hu=train_extract(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Italian\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/it/*.txt', recursive=True)\n",
    "\n",
    "lang='it'\n",
    "\n",
    "train_it=train_extract1(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Lithuanian\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/lt/*.txt', recursive=True)\n",
    "\n",
    "lang='lt'\n",
    "\n",
    "train_lt=train_extract(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Latvian\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/lv/*.txt', recursive=True)\n",
    "\n",
    "lang='lv'\n",
    "\n",
    "train_lv=train_extract(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Dutch\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/nl/*.txt', recursive=True)\n",
    "\n",
    "lang='nl'\n",
    "\n",
    "train_nl=train_extract1(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Polish\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/pl/*.txt', recursive=True)\n",
    "\n",
    "lang='pl'\n",
    "\n",
    "train_pl=train_extract(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Portugese\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/pt/*.txt', recursive=True)\n",
    "\n",
    "lang='pt'\n",
    "\n",
    "train_pt=train_extract1(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Romanian\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/ro/*.txt', recursive=True)\n",
    "\n",
    "lang='ro'\n",
    "\n",
    "train_ro=train_extract(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Slovak\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/sk/*.txt', recursive=True)\n",
    "\n",
    "lang='sk'\n",
    "\n",
    "train_sk=train_extract(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Slovene\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/sl/*.txt', recursive=True)\n",
    "\n",
    "lang='sl'\n",
    "\n",
    "train_sl=train_extract(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Swedish\n",
    "\n",
    "file_list = glob.glob('C:/Users/Arun/Notebooks/Fellowship.ai/europarl/txt/sv/*.txt', recursive=True)\n",
    "\n",
    "lang='sv'\n",
    "\n",
    "train_sv=train_extract1(file_list,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text Language\n",
      "0                          Състав на Парламента: вж.       bg\n",
      "1  протоколиОдобряване на протокола от предишното...       bg\n",
      "2             протоколиПроверка на пълномощията: вж.       bg\n",
      "3                 протоколиВнасяне на документи: вж.       bg\n",
      "4  протоколиВъпроси с искане за устен отговор и п...       bg\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all language training data into one combined training dataframe\n",
    "\n",
    "train_final=pd.concat([train_bg,train_cs,train_da,train_de,train_el,train_en,train_es,train_et,train_fi,train_fr,train_hu,train_it,train_lt,train_lv,train_nl,train_pl,train_pt,train_ro,train_sk,train_sl,train_sv])\n",
    "\n",
    "train_final=train_final.rename(columns={0:'Text'})\n",
    "\n",
    "print(train_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Text\n",
      "Language      \n",
      "bg         902\n",
      "cs         481\n",
      "da         783\n",
      "de         681\n",
      "el         579\n",
      "en         613\n",
      "es         621\n",
      "et         463\n",
      "fi         614\n",
      "fr         598\n",
      "hu         499\n",
      "it         565\n",
      "lt         872\n",
      "lv         938\n",
      "nl         764\n",
      "pl         531\n",
      "pt         579\n",
      "ro         471\n",
      "sk         475\n",
      "sl         576\n",
      "sv         705\n"
     ]
    }
   ],
   "source": [
    "# Count number of sentences in each language of combined training data.\n",
    "# This is to simply check if the training data has a good representation of all languages.\n",
    "\n",
    "train_count=train_final.groupby(['Language']).count()\n",
    "\n",
    "print(train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract testing data\n",
    "\n",
    "test=open('europarl_test.txt','rb').read()\n",
    "test=test.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ﻿bg\\t\"Европа 2020\" не трябва да стартира нов к...\n",
      "1    bg\\t(CS) Най-голямата несправедливост на сегаш...\n",
      "2    bg\\t(DE) Г-жо председател, г-н член на Комисия...\n",
      "3    bg\\t(DE) Г-н председател, бих искал да започна...\n",
      "4    bg\\t(DE) Г-н председател, въпросът за правата ...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Sentence tokenize test data\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "test1=pd.Series(nltk.sent_tokenize(test))\n",
    "\n",
    "print(test1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract sentence prefix from beginning of each sentence and build actual output\n",
    "\n",
    "test_lang=test1.str.extractall('(^bg|^cs|^da|^de|^el|^en|^es|^et|^fi|^fr|^hu|^it|^lt|^lv|^nl|^pl|^pt|^ro|^sk|^sl|^sv)')\n",
    "\n",
    "test_lang.reset_index(inplace=True)\n",
    "\n",
    "del test_lang['match']\n",
    "\n",
    "test_lang=test_lang.rename(columns={0:'Language','level_0':'key'})\n",
    "\n",
    "#print(test_lang.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove language prefix,\\t and other unneccessary text\n",
    "\n",
    "test_text=[pd.Series(re.sub(r\"(bg\\t)|(cs\\t)|(da\\t)|(de\\t)|(el\\t)|(en\\t)|(es\\t)|(et\\t)|(fi\\t)|(fr\\t)|(hu\\t)|(it\\t)|(lt\\t)|(lv\\t)|(nl\\t)|(pl\\t)|(pt\\t)|(ro\\t)|(sk\\t)|(sl\\t)|(sv\\t)|(\\(BG\\))|(\\(CS\\))|(\\(DA\\))|(\\(DE\\))|(\\(EL\\))|(\\(EN\\))|(\\(ES\\))|(\\(ET\\))|(\\(FI\\))|(\\(FR\\))|(\\(HU\\))|(\\(IT)\\)|(\\(LT)\\)|(\\(LV\\))|(\\(NL\\))|(\\(PL\\))|(\\(PT\\))|(\\(RO\\))|(\\(SK\\))|(\\(SL\\))|(\\(SV\\))\",'',i).strip()) for i in test1] \n",
    "\n",
    "#print(test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the dataframe containing text corpora\n",
    "\n",
    "test_text_df=pd.DataFrame(test_text)\n",
    "\n",
    "test_text_df.reset_index(inplace=True)\n",
    "\n",
    "test_text_df=test_text_df.rename(columns={0:'Text','index':'key'})\n",
    "\n",
    "#print(test_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join language feature to text corpora dataframe\n",
    "\n",
    "test_final=test_text_df.set_index('key').join(test_lang.set_index('key'))\n",
    "\n",
    "#print(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Text Language\n",
      "key                                                            \n",
      "0    ﻿\"Европа 2020\" не трябва да стартира нов конку...       bg\n",
      "1    Най-голямата несправедливост на сегашната обща...       bg\n",
      "2    Г-жо председател, г-н член на Комисията, по пр...       bg\n",
      "3    Г-н председател, бих искал да започна с комент...       bg\n",
      "4    Г-н председател, въпросът за правата на човека...       bg\n"
     ]
    }
   ],
   "source": [
    "# Backfill NA values of Language feature\n",
    "\n",
    "test_final1=test_final.copy()\n",
    "\n",
    "test_final1=test_final1.fillna(method='backfill')\n",
    "    \n",
    "print(test_final1.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training data into training(70%) and holdout(30%)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(train_final['Text'], \n",
    "                                                    train_final['Language'], \n",
    "                                                    random_state=0,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count vectorize training and holdout data\n",
    "# Build multinomial naive bayes classifier using training data\n",
    "# Fit this classifier on holdout data\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "cv=CountVectorizer()\n",
    "\n",
    "X_train_transformed=cv.fit_transform(X_train)\n",
    "X_holdout_transformed=cv.transform(X_holdout)\n",
    "    \n",
    "mnb=MultinomialNB(alpha=0.1)\n",
    "mnb.fit(X_train_transformed,y_train)\n",
    "y_pred_holdout=mnb.predict(X_holdout_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3993\n",
      "3993\n",
      "0.986977210118\n"
     ]
    }
   ],
   "source": [
    "# Check if actual values of holdout set and predicted values of holdout set have same length \n",
    "# Print accuracy of classifier on holdout set\n",
    "\n",
    "print(len(y_holdout))\n",
    "print(len(y_pred_holdout))\n",
    "\n",
    "print(np.mean(y_holdout==y_pred_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit same classifier on testing data\n",
    "\n",
    "X_test=test_final1['Text']\n",
    "y_test=test_final1['Language']\n",
    "\n",
    "X_test_transformed=cv.transform(X_test)\n",
    "\n",
    "mnb.fit(X_test_transformed,y_test)\n",
    "y_pred_test=mnb.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.962791541882\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy of classifier on testing dataset\n",
    "\n",
    "print(np.mean(y_test==y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Language  bg  cs  da  de  en  es  et  fr  hu  it  lt  lv  nl  pl  \\\n",
      "Actual Language                                                              \n",
      "bg                   0   0  28   0   0   0   0   0   0   0   0   0   0   0   \n",
      "cs                   0   0  63   0   2   0   0   0   1   0   2   0   0  15   \n",
      "da                   0   0   0   2   1   1   0   0   0   0   2   0   0   0   \n",
      "de                   0   1  11   0   0   1   0   0   0   0   0   0   0   0   \n",
      "el                   0   0   7   0   0   0   0   0   0   0   0   0   0   0   \n",
      "en                   0   0   3   1   0   1   1   0   0   0   0   0   0   0   \n",
      "es                   0   0   6   0   0   0   0   0   0   0   0   0   0   0   \n",
      "et                   0   0  72   1   4   0   0   0   1   1   1   0   2   0   \n",
      "fi                   0   0   8   0   0   0   3   0   0   0   0   0   0   0   \n",
      "fr                   0   0   4   0   0   0   0   0   0   0   0   0   0   0   \n",
      "hu                   0   0  56   0   0   1   0   0   0   1   1   0   4   0   \n",
      "it                   0   0   4   0   0   1   1   0   0   0   0   0   0   0   \n",
      "lt                   1   0  96   0   1   0   0   0   1   1   0   4   0   0   \n",
      "lv                   0   0  55   0   3   0   1   0   0   0  13   0   1   0   \n",
      "nl                   0   0   3   0   0   0   0   0   0   0   0   0   0   0   \n",
      "pl                   0   0  35   0   5   0   2   0   2   0   0   0   0   0   \n",
      "pt                   0   0   0   0   0   3   0   0   0   0   0   0   0   0   \n",
      "ro                   0   0  13   0   0   1   0   1   1   0   0   0   4   1   \n",
      "sk                   0  14  41   0   7   0   1   1   1   0   3   1   0  13   \n",
      "sl                   0   6  37   0   1   0   0   1   1   0   3   0   0   0   \n",
      "sv                   0   0   9   2   0   0   0   0   0   0   0   0   0   0   \n",
      "\n",
      "Predicted Language  pt  ro  sk  sl  sv  \n",
      "Actual Language                         \n",
      "bg                   0   0   0   0   0  \n",
      "cs                   0   2  29  22   0  \n",
      "da                   0   0   0   0   0  \n",
      "de                   0   2   0   0   0  \n",
      "el                   0   0   0   0   0  \n",
      "en                   0   0   0   0   0  \n",
      "es                   1   0   0   0   0  \n",
      "et                   0   1   2   1   0  \n",
      "fi                   0   0   0   0   0  \n",
      "fr                   0   0   0   0   0  \n",
      "hu                   0   1   0   0   0  \n",
      "it                   0   0   0   0   0  \n",
      "lt                   0   0   1   1   2  \n",
      "lv                   0   0   0   0   1  \n",
      "nl                   0   0   0   0   0  \n",
      "pl                   0   0  18   2   0  \n",
      "pt                   0   0   0   0   0  \n",
      "ro                   1   0   0   0   1  \n",
      "sk                   0   3   0  17   3  \n",
      "sl                   0   0   3   0   0  \n",
      "sv                   0   0   1   0   0  \n"
     ]
    }
   ],
   "source": [
    "# Try to find instances of misclassification\n",
    "# On testing set, build new binary column that shows 1 if classifier predicted \n",
    "# correctly else shows 0\n",
    "# Build new dataframe by only extracting misclassified instances of actual and predicted\n",
    "# language\n",
    "# Turn that dataframe into a matrix with actual language as rows and misclassified \n",
    "# predicted language as column.\n",
    "\n",
    "ml_df1=pd.DataFrame(y_test)\n",
    "ml_df2=pd.DataFrame(y_pred_test)\n",
    "\n",
    "ml_df1=ml_df1.rename(columns={'Language':'Actual Language'})\n",
    "\n",
    "ml_df2=ml_df2.rename(columns={0:'Predicted Language'})\n",
    "\n",
    "ml_df=ml_df1.join(ml_df2)\n",
    "\n",
    "ml_df['Match']=ml_df.apply(lambda x: 1 if x['Actual Language']==x['Predicted Language'] else 0, axis=1)\n",
    "\n",
    "ml_df_misclassified=ml_df[ml_df['Match']==0]\n",
    "\n",
    "ml_df_misclassified = ml_df_misclassified.groupby(['Actual Language','Predicted Language']).size().unstack(fill_value=0)\n",
    "\n",
    "print(ml_df_misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
